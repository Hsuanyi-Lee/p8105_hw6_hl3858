---
title: "p8105_hw6_hl3858"
output:
  github_document:
    toc: true
    toc_depth: 2
always_allow_html: true
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, warning = FALSE, message = FALSE, fig.retina = 2, fig.path = "figs/"
)

library(tidyverse)
library(broom)
library(purrr)
library(readr)
library(janitor)
library(modelr)
```

## Problem 0
- This repo is an R Project using git and GitHub for reproducibility.  
- A single R Markdown file `p8105_hw6_hl3858.Rmd` renders to `github_document`.  
- Local data files are stored in the `data/` folder and accessed via relative paths.  
- Figures are saved in the `figs/` folder.  
- The commit history reflects the working process.


## Problem 1: Logistic regression of homicide resolution

We use the Washington Post homicide dataset and follow the instructions to clean and analyze the data using logistic regression.

```{r}
dir.create("data", showWarnings = FALSE)

wp_url <- "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"
wp_path <- "data/homicide-data.csv"

if (!file.exists(wp_path)) {
  download.file(wp_url, destfile = wp_path, mode = "wb")
}

homicide <- read_csv(wp_path, show_col_types = FALSE) |>
  clean_names()
```

### Data cleaning

We create a `city_state` variable (e.g., “Baltimore, MD”), create a binary variable indicating whether the homicide is solved, remove the specified cities, ensure victim age is numeric, and restrict to white/black victims.

```{r}
homicide <- homicide |>
  mutate(
    city_state = str_c(str_to_title(city), ", ", state),
    resolved = case_when(
      disposition == "Closed by arrest" ~ 1,
      TRUE ~ 0
    ),
    victim_age = as.numeric(victim_age)
  ) |>
  filter(
    !(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")),
    victim_race %in% c("White", "Black")
  )
```

### Summary of cleaned data

```{r}
glimpse(homicide)
```

---

## Baltimore logistic regression

We fit a logistic regression for Baltimore, MD with outcome `resolved` and predictors victim age, sex, and race.

```{r}
balti <- homicide |> filter(city_state == "Baltimore, MD")

balti_glm <- glm(
  resolved ~ victim_age + victim_sex + victim_race,
  data = balti,
  family = binomial()
)

balti_tidy <- broom::tidy(balti_glm, conf.int = TRUE, exponentiate = TRUE)

balti_tidy |> filter(term == "victim_sexMale")
```

**Baltimore interpretation.**  
The adjusted odds ratio comparing **male vs female victims** in Baltimore, MD is approximately  
**0.43 (95% CI: 0.32–0.56)**.  
This indicates that homicides with male victims are **substantially less likely** to be solved than those with female victims, adjusting for age and race.

---

## Logistic regression for all cities

We run the same logistic regression model within each city and extract the adjusted OR for male vs female victims.
```{r}
city_models <- homicide |>
  group_by(city_state) |>
  nest() |>
  mutate(
    model = map(data, ~ glm(
      resolved ~ victim_age + victim_sex + victim_race,
      data = .x, family = binomial()
    )),
    tidied = map(model, ~ broom::tidy(.x, conf.int = TRUE, exponentiate = TRUE))
  ) |>
  unnest(tidied) |>
  filter(term == "victim_sexMale") |>
  select(city_state, estimate, conf.low, conf.high)

city_models <- city_models |>
  arrange(estimate) |>
  mutate(city_state = factor(city_state, levels = city_state))
```

### Plot of adjusted odds ratios
```{r}
ggplot(city_models, aes(x = estimate, y = city_state)) +
  geom_point() +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), height = 0) +
  geom_vline(xintercept = 1, linetype = "dashed") +
  labs(
    x = "Adjusted OR (male vs female)",
    y = "City",
    title = "Adjusted odds ratios for solving homicides (male vs female victims)",
    subtitle = "Logistic regression adjusted for age and race"
  )
```

**Interpretation.**  
Most cities show adjusted odds ratios **below 1**, indicating that homicides involving **male victims are less likely to be solved** than those involving female victims, controlling for age and race.  
The magnitude of this association varies by city, and some cities have **wide confidence intervals**, suggesting limited sample sizes.  
Only a few cities have ORs near or above 1, indicating little difference or the opposite pattern, although these often come with imprecise estimates.


## Problem 2: Bootstrap for regression summary statistics
We use the `weather_df` dataset from the `p8105.datasets` package and perform a nonparametric bootstrap to estimate the sampling distributions of  
- \( \hat r^2 \)  
- \( \hat\beta_1 / \hat\beta_2 \)  
from the regression:

\[
tmax = \beta_0 + \beta_1 tmin + \beta_2 prcp + \epsilon
\]

```{r}
library(p8105.datasets)
data("weather_df")

weather_df <- weather_df |>
  select(tmax, tmin, prcp) |>
  drop_na()
```

### Bootstrap setup
We take **5000 bootstrap samples**, refit the regression each time, extract:

- \( \hat r^2 \) using `broom::glance()`
- \( \hat\beta_1 \) and \( \hat\beta_2 \) using `broom::tidy()`
- compute the ratio \( \hat\beta_1 / \hat\beta_2 \)

```{r}
set.seed(8105)

boot_straps <- 
  modelr::bootstrap(weather_df, n = 5000)

boot_results <-
  boot_straps |>
  mutate(
    models = map(strap, ~ lm(tmax ~ tmin + prcp, data = .x)),
    glance_out = map(models, broom::glance),
    tidy_out   = map(models, broom::tidy)
  ) |>
  mutate(
    rsq = map_dbl(glance_out, "r.squared"),
    beta1 = map_dbl(tidy_out, ~ .x$estimate[.x$term == "tmin"]),
    beta2 = map_dbl(tidy_out, ~ .x$estimate[.x$term == "prcp"]),
    ratio = beta1 / beta2
  )
```

### Bootstrap distributions
```{r}
boot_results |>
  ggplot(aes(x = rsq)) +
  geom_histogram(bins = 50, fill = "skyblue", color = "white") +
  labs(title = "Bootstrap distribution of R-squared",
       x = expression(hat(r)^2), y = "Count")
```

```{r}
boot_results |>
  ggplot(aes(x = ratio)) +
  geom_histogram(bins = 50, fill = "salmon", color = "white") +
  labs(title = "Bootstrap distribution of beta1 / beta2",
       x = expression(hat(beta)[1] / hat(beta)[2]), y = "Count")
```

### 95% bootstrap confidence intervals
```{r}
rsq_ci <- quantile(boot_results$rsq, c(0.025, 0.975))
ratio_ci <- quantile(boot_results$ratio, c(0.025, 0.975))

rsq_ci
ratio_ci
```

### Interpretation
- The bootstrap distribution of \( \hat r^2 \) is tightly concentrated, suggesting the model explains a fairly consistent proportion of variability in `tmax`.  
- The distribution of \( \hat\beta_1 / \hat\beta_2 \) is wider and more skewed, reflecting higher uncertainty in the relative contribution of `tmin` and `prcp`.  
- The 95% bootstrap quantiles represent robust, nonparametric confidence intervals for both summaries.


## Problem 3: Modeling birthweight
We use the birthweight dataset to explore predictors of infant birthweight.

### Load & clean data
```{r}
birth_df <- read_csv("data/birthweight.csv") |>
  janitor::clean_names() |>
  mutate(
    babysex = factor(babysex, labels = c("male", "female")),
    frace   = factor(frace),
    mrace   = factor(mrace),
    malform = factor(malform),
    babysex = factor(babysex),
    parity = as.numeric(parity)
  ) |>
  drop_na()
```

Check missingness, structure:

```{r}
glimpse(birth_df)
```

---

## Proposed model for birthweight
I specify a model informed by biological reasoning:

- Birthweight increases with gestational age (gaweeks)  
- Birthweight increases with baby length (blength) and head circumference (bhead)  
- Mother's smoking decreases birthweight  
- Mother's weight gain and pre-pregnancy weight affect birthweight  
- Include maternal age (momage)

Proposed model:

```{r}
mod_main <- lm(
  bwt ~ blength + bhead + gaweeks + smoken + wtgain + momage,
  data = birth_df
)

summary(mod_main)
```

### Residuals vs fitted plot
```{r}
birth_df |>
  add_predictions(mod_main) |>
  add_residuals(mod_main) |>
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.4) +
  geom_hline(yintercept = 0, color = "red") +
  labs(
    title = "Residuals vs fitted values for proposed model",
    x = "Fitted values",
    y = "Residuals"
  )
```

---

## Comparison models
### Model 2: Length + gest age only
```{r}
mod_simple <- lm(bwt ~ blength + gaweeks, data = birth_df)
```

### Model 3: Full interaction model
```{r}
mod_interact <- lm(
  bwt ~ babysex * blength * bhead,
  data = birth_df
)
```

---

## Cross-validated prediction error
We use Mont Carlo cross-validation with 100 folds.
```{r}
set.seed(8105)

cv_df <- crossv_mc(birth_df, n = 100, test = 0.2)

cv_results <- cv_df |>
  mutate(
    train_df = map(train, as.data.frame),
    test_df  = map(test,  as.data.frame),

    mod_main = map(train_df, ~ lm(bwt ~ blength + bhead + gaweeks + smoken + wtgain + momage, data = .x)),
    mod_simple = map(train_df, ~ lm(bwt ~ blength + gaweeks, data = .x)),
    mod_interact = map(train_df, ~ lm(bwt ~ babysex * blength * bhead, data = .x)),

    rmse_main = map2_dbl(mod_main, test_df, ~ {
      preds <- predict(.x, newdata = .y)
      sqrt(mean((preds - .y$bwt)^2))
    }),

    rmse_simple = map2_dbl(mod_simple, test_df, ~ {
      preds <- predict(.x, newdata = .y)
      sqrt(mean((preds - .y$bwt)^2))
    }),

    rmse_interact = map2_dbl(mod_interact, test_df, ~ {
      preds <- predict(.x, newdata = .y)
      sqrt(mean((preds - .y$bwt)^2))
    })
  )
```


### RMSE comparison
```{r}
cv_summary <- cv_results |>
  summarize(
    main_rmse = mean(rmse_main),
    simple_rmse = mean(rmse_simple),
    interact_rmse = mean(rmse_interact)
  )

cv_summary
```

---

## Interpretation
- The **simple model** (length + gest age) generally performs worse.  
- The **three-way interaction model** tends to overfit and shows higher RMSE.  
- The **proposed biologically-motivated model** achieves the best prediction error across folds, indicating it captures meaningful structure without unnecessary complexity.  

Overall, the proposed model balances interpretability and predictive accuracy.

